# -*- coding: utf-8 -*-
"""PubMed Research Digest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M6frNUaMKtZHcFD3FtErDigGelJeysud
"""

"""
PubMed Research Digest
Automated literature search, ranking, and email digest system
"""

# ============================
# 1. Install Dependencies
# ============================

!pip install biopython sentence-transformers transformers torch
!pip install google-auth-oauthlib google-auth-httplib2 google-api-python-client


# ============================
# 2. Import Libraries
# ============================

from Bio import Entrez
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline
import base64
from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import pickle
import os
from google.colab import files


# ============================
# 3. PubMed Fetch
# ============================

Entrez.email = "enteryour@gmail.com"

def fetch_pubmed(query, max_results=10):
    handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results, sort="relevance")
    record = Entrez.read(handle)
    ids = record["IdList"]

    papers = []
    if ids:
        handle = Entrez.efetch(db="pubmed", id=",".join(ids), rettype="abstract", retmode="xml")
        records = Entrez.read(handle)
        for article in records["PubmedArticle"]:
            try:
                title = article["MedlineCitation"]["Article"]["ArticleTitle"]
                # Better abstract handling for structured abstracts
                abstract_parts = article["MedlineCitation"]["Article"].get("Abstract", {}).get("AbstractText", [])
                abstract = " ".join([str(part) for part in abstract_parts]) if abstract_parts else "No abstract available"
                papers.append({"title": title, "abstract": abstract})
            except KeyError:
                continue
    return papers


# ============================
# 4. Embedding Model for Ranking
# ============================

model = SentenceTransformer("all-MiniLM-L6-v2")

def rank_papers(papers, interest):
    interest_emb = model.encode(interest, convert_to_tensor=True)
    for p in papers:
        paper_emb = model.encode(p["abstract"], convert_to_tensor=True)
        p["score"] = util.cos_sim(interest_emb, paper_emb).item()
    return sorted(papers, key=lambda x: x["score"], reverse=True)


# ============================
# 5. Summarizer
# ============================

summarizer = pipeline("summarization", model="facebook/bart-large-cnn", device=-1)  # -1 for CPU, 0 for GPU

def summarize_text(text, max_len=100):
    # Remove "No abstract available" from summarization
    if text == "No abstract available" or len(text.split()) < 40:
        return text

    # Truncate if too long (BART has 1024 token limit)
    words = text.split()
    if len(words) > 400:
        text = " ".join(words[:400])

    try:
        summary = summarizer(
            text, max_length=max_len, min_length=30, do_sample=False
        )[0]["summary_text"]
        return summary
    except Exception as e:
        return text[:200] + "..."  # Fallback to truncation


# ============================
# 6. Gmail authentication
# ============================

SCOPES = ['https://www.googleapis.com/auth/gmail.send']

def gmail_authenticate():
    creds = None
    if os.path.exists("token.pkl"):
        with open("token.pkl", "rb") as token:
            creds = pickle.load(token)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                "credentials.json",
                SCOPES,
                redirect_uri='urn:ietf:wg:oauth:2.0:oob'
            )

            # Get the authorization URL
            auth_url, _ = flow.authorization_url(prompt='consent')

            print("\n" + "="*60)
            print("üîê GMAIL AUTHENTICATION REQUIRED")
            print("="*60)
            print("\n1. Click on this URL to authorize:")
            print(f"\n{auth_url}\n")
            print("2. After authorizing, copy the authorization code")
            print("3. Paste it below\n")

            code = input("Enter the authorization code: ").strip()
            flow.fetch_token(code=code)
            creds = flow.credentials

        with open("token.pkl", "wb") as token:
            pickle.dump(creds, token)

    return build("gmail", "v1", credentials=creds)

def send_email(service, recipient, subject, body):
    message = f"From: me\nTo: {recipient}\nSubject: {subject}\n\n{body}"
    encoded_message = base64.urlsafe_b64encode(message.encode("utf-8")).decode("utf-8")
    send_message = {"raw": encoded_message}
    service.users().messages().send(userId="me", body=send_message).execute()


# ============================
# 7. Upload credentials.json
# ============================

print("üìÇ Please upload your credentials.json file")
uploaded = files.upload()


# ============================
# 8. Run PubMed search
# ============================

interests = [
    "cancer genomics",
    "brain organoids",
    "bioengineering",
    "advanced diagnostics and biomarkers",
    "regenerative medicine",
    "precision medicine",
    "nanomedicine",
    "synthetic biology",
    "biomaterials and bioelectronics",
    "AI in biology"
]

all_results = []

print("üîç Fetching and processing papers...")
for i, interest in enumerate(interests, 1):
    print(f"  [{i}/{len(interests)}] Processing: {interest}")
    papers = fetch_pubmed(interest, max_results=15)
    ranked = rank_papers(papers, interest)[:5]
    for p in ranked:
        p["summary"] = summarize_text(p["abstract"])
        p["topic"] = interest
    all_results.extend(ranked)


# ============================
# 9. Format email body
# ============================

body = "üìö Your Personalized PubMed Research Digest\n"
body += "=" * 60 + "\n"

for topic in interests:
    topic_papers = [r for r in all_results if r["topic"] == topic]
    if topic_papers:
        body += f"\n\nüîπ Topic: {topic.upper()}\n"
        body += "-" * 60 + "\n"
        for p in topic_papers:
            body += f"\nüìÑ Title: {p['title']}\n"
            body += f"   Relevance Score: {p['score']:.2f}\n"
            body += f"   Summary: {p['summary']}\n"


# ============================
# 10. Send email
# ============================

print("\nüìß Authenticating with Gmail...")
service = gmail_authenticate()
print("üì§ Sending email...")
send_email(service, "enteryour@gmail.com", "Your PubMed Digest", body)
print("‚úÖ Email sent successfully!")
